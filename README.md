# BALE (Bimodal Affective LEarning)
This repository contains the code for the paper *Decoding affective states without labels: bimodal image-brain supervision* submitted to *ACM International Conference on Multimodal Interaction*. 

Details about how to run the code will be uploaded on May 4.

## Install dependencies

``uv`` is used as package manager. To install the dependencies, run:
```py
uv sync
```

## Download the data
TODO

## Pepare the data
TODO

## Run the training
```py
uv run python run.py
```

## Generate the results and the figures
```py
uv run python generate_results_figures.py
```